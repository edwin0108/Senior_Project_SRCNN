{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spuer_Resolution.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "etoWJCqqBBJq"
      },
      "cell_type": "markdown",
      "source": [
        "# Import Section"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "BuXTXaiWBBQK",
        "outputId": "66af0fcc-cc1c-4eda-c8be-c5c68c0c43b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "cell_type": "code",
      "source": [
        "# Path\n",
        "import os\n",
        "\n",
        "# Data\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# Plot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Image\n",
        "from PIL import Image # used in image processing function\n",
        "from PIL import ImageFilter # used in load_image_pair()\n",
        "\n",
        "# Tensorflow\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "\n",
        "# For Tensorflow Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "\n",
        "!pip install tensorboard"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (1.13.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.14.6)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.33.1)\n",
            "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.15.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (3.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.7.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.11.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (3.6.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.0->tensorboard) (40.8.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "pAr52j3pAKOZ"
      },
      "cell_type": "markdown",
      "source": [
        "# Colab Function"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "7BI277Ug8aiC",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def gpu_check():\n",
        "  \"\"\"\n",
        "      Check GPU RAM status. Since google colab share gpu resource amount of its\n",
        "      user, you want to make sure there are enough GPU RAM that are free to use.\n",
        "      Recommend at least 3000MB free GPU RAM.\n",
        "  \"\"\"\n",
        "  # memory footprint support libraries/code\n",
        "  !ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "  !pip install gputil\n",
        "  !pip install psutil\n",
        "  !pip install humanize\n",
        "  import psutil\n",
        "  import humanize\n",
        "  import os\n",
        "  import GPUtil as GPU\n",
        "  GPUs = GPU.getGPUs()\n",
        "  # XXX: only one GPU on Colab and isn’t guaranteed\n",
        "  gpu = GPUs[0]\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "jCYudY3lCm9Y"
      },
      "cell_type": "markdown",
      "source": [
        "# Path Functions"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "m8cFuFGVCmUi",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def ensure_dir(path_to_dir):\n",
        "  try:\n",
        "      os.makedirs(path_to_dir)\n",
        "  except FileExistsError:\n",
        "      # directory already exists\n",
        "      pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Cy0RU340NMu7"
      },
      "cell_type": "markdown",
      "source": [
        "# Config"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aC2LlAquNz8_",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "    config project in this cell.\n",
        "\"\"\"\n",
        "\n",
        "# Env, where you running this project\n",
        "# Google colab: 'colab'\n",
        "# local machine: 'local'\n",
        "env = 'colab'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-RshcPfONLU2",
        "outputId": "f534e863-2c62-4213-c64e-cf2ecf446b0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\" \n",
        "     _______________________________________________\n",
        "    | YOU SHOULD NOT CHANGE ANY THING IN THIS CELL. |\n",
        "    |_______________________________________________|\n",
        "\"\"\"\n",
        "\n",
        "# config dictionary\n",
        "config = {\n",
        "    'colab':{\n",
        "        'data_dir':'/content/drive/My Drive/Colab Notebooks/data',\n",
        "        'checkpoint_dir':'/content/drive/My Drive/Colab Notebooks/checkpoints',\n",
        "        'log_dir':'/content/drive/My Drive/Colab Notebooks/logs',\n",
        "    },\n",
        "    'local':{\n",
        "        'data_dir': os.path.join(os.getcwd(), 'data'),\n",
        "        'checkpoint_dir': os.path.join(os.getcwd(), 'checkpoints'),\n",
        "        'log_dir': os.path.join(os.getcwd(), 'logs'),\n",
        "    }\n",
        "}\n",
        "\n",
        "# setting all variables\n",
        "data_dir = config[env]['data_dir']\n",
        "checkpoint_dir = config[env]['checkpoint_dir']\n",
        "log_dir = config[env]['log_dir']\n",
        "\n",
        "# mount google drive\n",
        "if env == 'colab':\n",
        "  # Google Drive\n",
        "  from google.colab import drive\n",
        "  # mount google dirve\n",
        "  drive.mount('/content/drive')\n",
        "  # ensure dir exsits\n",
        "  ensure_dir(checkpoint_dir)\n",
        "  # check GPU\n",
        "  gpu_check()\n",
        "  \n",
        "# make sure dir exist\n",
        "ensure_dir(checkpoint_dir)\n",
        "ensure_dir(log_dir)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.8 GB  | Proc size: 307.7 MB\n",
            "GPU RAM Free: 11441MB | Used: 0MB | Util   0% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "kDu_20FxAARs"
      },
      "cell_type": "markdown",
      "source": [
        "# Image Processing Function"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "c_98TDEO_pzJ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def bicubic_rescale(image, scale):\n",
        "  \"\"\"\n",
        "      Rescale image using bicubic interpolation.\n",
        "      \n",
        "      Args:\n",
        "        image: image\n",
        "        scale: use integer for up scaling. use 1/integer for down scaling\n",
        "  \"\"\"\n",
        "  # make sure scale is valid\n",
        "  if isinstance(scale, (float, int)):\n",
        "    size = (np.array(image.size) * scale).astype(int)\n",
        "  '''\n",
        "  WARNING\n",
        "  image.resize might lead to image displacement\n",
        "  https://hackernoon.com/how-tensorflows-tf-image-resize-stole-60-days-of-my-life-aba5eb093f35\n",
        "  switch to tf.image.resize_bicubic\n",
        "  '''\n",
        "  return image.resize(size, resample=Image.BICUBIC)\n",
        "\n",
        "\n",
        "def modcrop(image, scale):\n",
        "  \"\"\"\n",
        "      To scale down the original image, there must be no remainder while scaling\n",
        "      operation.\n",
        "      \n",
        "      All we want to do in here is to subtract the remainder from height and \n",
        "      width of original image size, and cut the original image to the new size.\n",
        "      \n",
        "      Args:\n",
        "        image: original image\n",
        "        scale: must be int\n",
        "  \"\"\"\n",
        "  if not isinstance(scale, int):\n",
        "    raise Exception('utils.modcrop: scale must be int')\n",
        "  size = np.array(image.size)\n",
        "  size -= size % scale\n",
        "  return image.crop([0, 0, *size])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "kQdMEWBzeZUZ"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Q2pYcMrkefv7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_image_pair(path, scale=3, greyscale=False, same_size=False):\n",
        "  \"\"\"\n",
        "      Down scaling a hight resolution image to a low resolution image and\n",
        "      return both of them.\n",
        "      \n",
        "      Args:\n",
        "        path: image path\n",
        "        scale: scale of down scaling, must be a int\n",
        "        greyscale: return only Y channel\n",
        "  \"\"\"\n",
        "  image = load_img(path)\n",
        "  \n",
        "  if greyscale:\n",
        "    image = image.convert('YCbCr')\n",
        "    Y, Cb, Cr = image.split()\n",
        "    image = Y\n",
        "  else:\n",
        "    image = image.convert('RGB')\n",
        "\n",
        "  hr_image = modcrop(image, scale)\n",
        "  lr_image = hr_image.filter(ImageFilter.GaussianBlur(radius=2))\n",
        "  lr_image = bicubic_rescale(lr_image, 1 / scale)\n",
        "  lr_image = bicubic_rescale(lr_image, scale)\n",
        "  return lr_image, hr_image\n",
        "\n",
        "\n",
        "def random_crop(lr_image, hr_image, random_crop_size):\n",
        "  \"\"\"\n",
        "      randomly crop both lr and hr image at the same position.\n",
        "      \n",
        "      Args:\n",
        "          random_crop_size: size of sub image, array, example:[32,32]\n",
        "  \"\"\"\n",
        "  # Note: image_data_format is 'channel_last'\n",
        "  height, width = lr_image.size\n",
        "  dy, dx = random_crop_size\n",
        "  x = np.random.randint(0, width - dx + 1)\n",
        "  y = np.random.randint(0, height - dy + 1)\n",
        "  return lr_image.crop([x, y, x + dx, y + dy]), hr_image.crop([x, y, x + dx, y + dy])\n",
        "\n",
        "\n",
        "def generate_sub_images(lr_image, hr_image, size=[32, 32], num_of_image=1):\n",
        "  \"\"\"\n",
        "      Cut image into sub images.\n",
        "      \n",
        "      Args:\n",
        "        image: image\n",
        "        size: size of sub image\n",
        "        number_of_image: how many sub image you want to crop for image\n",
        "  \"\"\"\n",
        "  for i in range(num_of_image):\n",
        "    yield random_crop(lr_image, hr_image, size)\n",
        "            \n",
        "            \n",
        "class Dataset:\n",
        "  \n",
        "  def __init__(self):\n",
        "    self.lr_sub_size = 0\n",
        "    self.lr_sub_stride = 0\n",
        "    self.hr_sub_size = 0\n",
        "    self.hr_sub_stride = 0\n",
        "    self.lr_array = []\n",
        "    self.hr_array = []\n",
        "    self.greyscale = False\n",
        "    \n",
        "    \n",
        "  def load_set(self, dataset_name, lr_sub_size, lr_sub_stride, scale, same_size=False, greyscale=False):\n",
        "    \"\"\"\n",
        "        Load all image from a directory and cut them into small sub image.\n",
        "\n",
        "        Args:\n",
        "          dataset_name: name of dir of the data set\n",
        "          lr_sub_size: low resolution sub image size\n",
        "          lr_sub_stride: stride when crop sub image\n",
        "          scale: down scale value\n",
        "          same_size: hr, lr have the same size\n",
        "          greyscale: return only Y channel\n",
        "    \"\"\"\n",
        "    if not all(isinstance(i, int) for i in [lr_sub_size, lr_sub_stride, scale]):\n",
        "      raise Exception('utils.load_set: lr_sub_size, stride, scale must be int')\n",
        "      \n",
        "    self.lr_sub_size = lr_sub_size\n",
        "    self.lr_sub_stride = lr_sub_stride\n",
        "    self.greyscale = greyscale\n",
        "      \n",
        "    # compute parameters for hight resolution image\n",
        "    if same_size:\n",
        "      self.hr_sub_size = lr_sub_size\n",
        "      self.hr_sub_stride = lr_sub_stride\n",
        "    else:\n",
        "      self.hr_sub_size = lr_sub_size * scale\n",
        "      self.hr_sub_stride = lr_sub_stride * scale\n",
        "    \n",
        "    for file_name in os.listdir(os.path.join(data_dir, dataset_name)):\n",
        "      path = os.path.join(data_dir, dataset_name, file_name)\n",
        "      lr_image, hr_image = load_image_pair(str(path), scale=scale, greyscale=greyscale, same_size=same_size)\n",
        "      self.lr_array.append(lr_image)\n",
        "      self.hr_array.append(hr_image)\n",
        "      \n",
        "      \n",
        "  def show_set(self):\n",
        "    \"\"\"\n",
        "      view the first 3 image of the dataset\n",
        "    \"\"\"\n",
        "    if self.greyscale:\n",
        "      colormap = 'gray'\n",
        "    else:\n",
        "      colormap = None\n",
        "      \n",
        "    f, axarr = plt.subplots(2, 3, figsize=(18,18))\n",
        "    \n",
        "    # Plot images in subplot\n",
        "    axarr[1,2].imshow(self.hr_array[0], cmap=colormap)\n",
        "    axarr[1,1].imshow(self.hr_array[1], cmap=colormap)\n",
        "    axarr[1,0].imshow(self.hr_array[2], cmap=colormap)\n",
        "    axarr[0,2].imshow(self.lr_array[0], cmap=colormap)\n",
        "    axarr[0,1].imshow(self.lr_array[1], cmap=colormap)\n",
        "    axarr[0,0].imshow(self.lr_array[2], cmap=colormap)\n",
        "    \n",
        "    # Disable axis\n",
        "    axarr[1,2].axis(\"off\")\n",
        "    axarr[1,1].axis(\"off\")\n",
        "    axarr[1,0].axis(\"off\")\n",
        "    axarr[0,2].axis(\"off\")\n",
        "    axarr[0,1].axis(\"off\")\n",
        "    axarr[0,0].axis(\"off\")\n",
        "   \n",
        "    plt.show()\n",
        "    \n",
        "  \n",
        "  def sub_image_set(self, random_crop_size=[32,32], num_of_image=1):\n",
        "    \"\"\"\n",
        "      return the sub image dataset\n",
        "    \"\"\"\n",
        "    lr_sub_arrays = []\n",
        "    hr_sub_arrays = []\n",
        "    lr_batch = []\n",
        "    hr_batch = []\n",
        "    height, width = self.hr_array[0].size\n",
        "    dy, dx = random_crop_size\n",
        "    \n",
        "    # crop low resolution image and high resolution image at same position\n",
        "    for lr_image, hr_image in zip(self.lr_array, self.hr_array):\n",
        "      for i in range(num_of_image):\n",
        "        x = np.random.randint(0, width - dx + 1)\n",
        "        y = np.random.randint(0, height - dy + 1)\n",
        "        \n",
        "        lr_batch += [lr_image.crop([x, y, x + dx, y + dy])]\n",
        "        hr_batch += [hr_image.crop([x, y, x + dx, y + dy])]\n",
        "        \n",
        "      lr_sub_arrays += [img_to_array(img) for img in lr_batch]\n",
        "      hr_sub_arrays += [img_to_array(img) for img in hr_batch]\n",
        "    \n",
        "    # convert list to np.array\n",
        "    x = np.stack(lr_sub_arrays)\n",
        "    y = np.stack(hr_sub_arrays)\n",
        "\n",
        "    return x, y \n",
        "\n",
        "  def clear_set(self):\n",
        "    \"\"\"\n",
        "      reset Dataset\n",
        "    \"\"\"\n",
        "    self.lr_array = []\n",
        "    self.hr_array = []\n",
        "    \n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "_YdOAzDpH50m"
      },
      "cell_type": "markdown",
      "source": [
        "# Helper Function"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6ra2c266H5U5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(\n",
        "    model,\n",
        "    train_set,\n",
        "    val_set,\n",
        "    epochs=1,\n",
        "    steps_per_epoch=30,\n",
        "    validation_steps=3,\n",
        "    resume=True):\n",
        "  \"\"\"\n",
        "    train function for all model.\n",
        "    \n",
        "    \n",
        "  \"\"\"\n",
        "  path_to_weight_file = os.path.join(checkpoint_dir,model.name)\n",
        "\n",
        "  # define callbacks\n",
        " \n",
        "    # Save checkpoints of model at regular intervals\n",
        "  callbacks = [\n",
        "    # Save checkpoints of model at regular intervals\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=path_to_weight_file,\n",
        "        save_best_only=True\n",
        "    ),\n",
        "    # Write TensorBoard logs to `./logs` directory\n",
        "      tf.keras.callbacks.TensorBoard(log_dir='./Graph')\n",
        "  ]\n",
        "  \n",
        "  # inherit weights\n",
        "  \n",
        "  if resume:\n",
        "    model.load_weights(path_to_weight_file)\n",
        "  \n",
        "  # Train\n",
        "  #callbacks.set_model(model)\n",
        "\n",
        "  model.fit(train_set, epochs=epochs,verbose=0, callbacks=callbacks, steps_per_epoch=steps_per_epoch,\n",
        "            validation_data=val_set, validation_steps=validation_steps)\n",
        "  \n",
        "\n",
        "\n",
        "  # plot metrics\n",
        "  #plot_based_loss(history)\n",
        "  #plot_based_accuracy(history)\n",
        "  \n",
        "  \n",
        "\n",
        "def test(model, test_set, steps=30, metrics=None):\n",
        "  # test\n",
        "  model.evaluate(test_set, steps=steps)\n",
        "  \n",
        "def reload_model(model):\n",
        "  \"\"\"\n",
        "    load weight into model\n",
        "  \"\"\"\n",
        "  path_to_weight_file = os.path.join(checkpoint_dir,model.name)\n",
        "  model.load_weights(path_to_weight_file)\n",
        "  \n",
        "def plot_based_loss(history):\n",
        "  \"\"\"\n",
        "    Plot training & validation loss values\n",
        "    history: a dictionary recording training loss values and metrics values at successive epochs\n",
        "  \"\"\"\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('Model loss: Mean Squared Error')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "  plt.ylim(0,2000)\n",
        "  plt.show()\n",
        "  \n",
        "def plot_based_accuracy(history):\n",
        "  \"\"\"\n",
        "    Plot training & validation accuracy values\n",
        "    history: a dictionary recording training loss values and metrics values at successive epochs\n",
        "  \"\"\"\n",
        "  plt.plot(history.history['acc'])\n",
        "  plt.plot(history.history['val_acc'])\n",
        "  plt.title('Model accuracy: Accuracy')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Njz9qRTbR2eC"
      },
      "cell_type": "markdown",
      "source": [
        "# Model"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aopmTkWXR5Yt",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SRCNN:\n",
        "  \"\"\"\n",
        "    name: the name of the model\n",
        "    img_size: the size of the input image\n",
        "    channel: the number of channels in the input image\n",
        "    f1: the size of filter (must be odd #)\n",
        "    n1: the number of filters apply on layer 1\n",
        "    n2: the number of filters apply on layer 2\n",
        "    f3: the size of filter (must be odd #)\n",
        "\n",
        "\n",
        "    from: https://arxiv.org/abs/1501.00092\n",
        "  \"\"\" \n",
        "  def build_model(img_size=32, channel=1, f1=9, n1=64, n2=32, f3=5):\n",
        "    model = Sequential(name='srcnn')\n",
        "    initializer = RandomNormal(mean=0.0, stddev=0.001)\n",
        "    model.add(Conv2D(filters=n1, kernel_size=f1, padding='same', activation='relu',\n",
        "                     kernel_initializer=initializer, input_shape=(img_size,img_size,channel)))\n",
        "    model.add(Conv2D(filters=n2, kernel_size=1, padding='same', activation='relu',\n",
        "                    kernel_initializer=initializer))\n",
        "    model.add(Conv2D(filters=channel, kernel_size=f3, padding='same', activation='linear',\n",
        "                    kernel_initializer=initializer))\n",
        "  \n",
        "    # either SGD or Adam\n",
        "    #optimizer = SGD(lr=0.0003)\n",
        "    optimizer = Adam(lr=0.0003)\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['acc'])\n",
        "      \n",
        "    return model\n",
        "    \n",
        "\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6xQkZ4GeHdRI",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "2cgYjtF81t1s"
      },
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "SGkYBCzi2AWC"
      },
      "cell_type": "markdown",
      "source": [
        "## Model Config"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "h9UOu_Bm1uPg",
        "outputId": "a282ad13-da72-46bf-c177-0cc898ae19a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "cell_type": "code",
      "source": [
        "# size of sub image\n",
        "size = 32\n",
        "\n",
        "# strde when crop image\n",
        "stride = 14\n",
        "\n",
        "# upscaling factor\n",
        "scale = 1\n",
        "\n",
        "# batch size\n",
        "batch = 32\n",
        "\n",
        "# size of low resolution and high resolution image is the same?\n",
        "same_size = True\n",
        "\n",
        "# number of sub image of each image\n",
        "num_of_image = 30\n",
        "\n",
        "# greyscale ON or OFF? if ON, img will only contain Y channel\n",
        "greyscale = True\n",
        "\n",
        "# whcih training dataset you want to use?\n",
        "train_dataset_dir = '91-image'\n",
        "\n",
        "# which validation dataset you want to use?\n",
        "val_dataset_dir = 'Set5'\n",
        "\n",
        "# which testing dataset you want to use?\n",
        "test_dataset_dir = 'Set14'\n",
        "\n",
        "# which model you want to train or test?\n",
        "model = SRCNN.build_model(size)\n",
        "\n",
        "# print model details below\n",
        "print(\"Model Name: {}\".format(model.name))\n",
        "model.summary()\n",
        "\n",
        "# epochs\n",
        "epochs = 3\n",
        "\n",
        "# steps_per_epoch\n",
        "steps_per_epoch = 30\n",
        "\n",
        "# validation_steps\n",
        "validation_steps = 3\n",
        "\n",
        "# resume last traning?\n",
        "resume = False\n",
        "    "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-16de5d147ea1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# which model you want to train or test?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSRCNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# print model details below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SRCNN' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "p2KU8_I55mV_"
      },
      "cell_type": "markdown",
      "source": [
        "## Make Data"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "PXgxe40I4OWB",
        "outputId": "c07deacb-073a-4784-d88c-a1fc2ad7b688",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\" \n",
        "     _______________________________________________\n",
        "    | YOU SHOULD NOT CHANGE ANY THING IN THIS CELL. |\n",
        "    |_______________________________________________|\n",
        "\"\"\"\n",
        "dataset = Dataset()\n",
        "\n",
        "# load tranning dataset\n",
        "dataset.load_set(train_dataset_dir, size, stride, scale, same_size, greyscale)\n",
        "dataset.show_set()\n",
        "train_lr, train_hr = dataset.sub_image_set([size, size], num_of_image)\n",
        "\n",
        "# make tf.data dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_lr, train_hr))\n",
        "train_dataset = train_dataset.batch(batch)\n",
        "train_dataset = train_dataset.repeat()\n",
        "\n",
        "# load validation dataset\n",
        "dataset.clear_set()\n",
        "dataset.load_set(val_dataset_dir, size, stride, scale, same_size, greyscale)\n",
        "val_lr, val_hr = dataset.sub_image_set([size, size], num_of_image)\n",
        "# make tf.data dataset\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_lr, val_hr))\n",
        "val_dataset = val_dataset.batch(batch//10)\n",
        "val_dataset = val_dataset.repeat()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-753f9944373a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m|\u001b[0m\u001b[0m_______________________________________________\u001b[0m\u001b[0;34m|\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \"\"\"\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# load tranning dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qEco354UZowl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1459
        },
        "outputId": "c6eb21c5-cd45-4520-9bc9-e8d800234739"
      },
      "cell_type": "code",
      "source": [
        "\"\"\" \n",
        "    _________\n",
        "    | Train |\n",
        "    ————-\n",
        "     _______________________________________________\n",
        "    | YOU SHOULD NOT CHANGE ANY THING IN THIS CELL. |\n",
        "    |_______________________________________________|\n",
        "\"\"\"\n",
        "train(model, train_dataset, val_dataset, epochs, steps_per_epoch, validation_steps, resume)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-ed0ff256b3fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;34m|\u001b[0m\u001b[0m_______________________________________________\u001b[0m\u001b[0;34m|\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \"\"\"\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-e4206bd7b866>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_set, val_set, epochs, steps_per_epoch, validation_steps, resume)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m   model.fit(train_set, epochs=epochs,verbose=0, callbacks=callbacks, steps_per_epoch=steps_per_epoch,\n\u001b[0;32m---> 38\u001b[0;31m             validation_data=val_set, validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m       \u001b[0msamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_samples_or_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m       \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Handle ProgBarLogger separately in this loop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m       mode=mode)\n\u001b[0m\u001b[1;32m    216\u001b[0m   \u001b[0;31m# TODO(omalleyt): Handle ProgBar as part of Callbacks once hooks are ready.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m   \u001b[0mprogbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mconfigure_callbacks\u001b[0;34m(callbacks, model, do_validation, batch_size, epochs, steps_per_epoch, samples, verbose, count_mode, mode)\u001b[0m\n\u001b[1;32m    104\u001b[0m   \u001b[0;31m# Set callback model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0mcallback_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_callback_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m   \u001b[0mcallback_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m   \u001b[0;31m# Set callback parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mset_model\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m       \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mset_model\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m     \u001b[0;31m# histogram summaries only enabled in graph mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_init_writer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummary_ops_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_file_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_summary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_summary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/summary/writer/writer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, logdir, graph, max_queue, flush_secs, graph_def, filename_suffix, session)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_writer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/summary/writer/writer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, event_writer, graph, graph_def)\u001b[0m\n\u001b[1;32m     89\u001b[0m       self.add_meta_graph(\n\u001b[1;32m     90\u001b[0m           meta_graph.create_meta_graph_def(graph_def=graph_def or\n\u001b[0;32m---> 91\u001b[0;31m                                            maybe_graph_as_def))\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# This set contains tags of Summary Values that have been encountered\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/summary/writer/writer.py\u001b[0m in \u001b[0;36madd_meta_graph\u001b[0;34m(self, meta_graph_def, global_step)\u001b[0m\n\u001b[1;32m    246\u001b[0m                       type(meta_graph_def))\n\u001b[1;32m    247\u001b[0m     \u001b[0mmeta_graph_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevent_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta_graph_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "7dLCxfBygfwk",
        "colab_type": "code",
        "outputId": "585b9d8d-49d7-468d-de5f-2571250898d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "cell_type": "code",
      "source": [
        "!tensorboard --logdir ./Graph"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorBoard 1.13.0 at http://f32770e424d8:6006 (Press CTRL+C to quit)\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Pl8Lxx4ktTpj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\" \n",
        "    ___________\n",
        "    | Reload  |\n",
        "    ————---\n",
        "     _______________________________________________\n",
        "    | YOU SHOULD NOT CHANGE ANY THING IN THIS CELL. |\n",
        "    |_______________________________________________|\n",
        "\"\"\"\n",
        "reload_model(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-DShHp24VRFR",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\" \n",
        "     _______________________________________________\n",
        "    | YOU SHOULD NOT CHANGE ANY THING IN THIS CELL. |\n",
        "    |_______________________________________________|\n",
        "\"\"\"\n",
        "dataset = Dataset()\n",
        "\n",
        "# load test dataset\n",
        "dataset.load_set(test_dataset_dir, size, stride, scale, same_size, greyscale)\n",
        "dataset.show_set()\n",
        "test_lr, test_hr = dataset.sub_image_set([size, size], num_of_image)\n",
        "\n",
        "# make tf.data dataset\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_lr, test_hr))\n",
        "test_dataset = test_dataset.batch(batch)\n",
        "test_dataset = test_dataset.repeat()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Zxbfh3taVMfZ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\" \n",
        "    _________\n",
        "    | Test  |\n",
        "    ————-\n",
        "     _______________________________________________\n",
        "    | YOU SHOULD NOT CHANGE ANY THING IN THIS CELL. |\n",
        "    |_______________________________________________|\n",
        "\"\"\"\n",
        "test(model, test_dataset, steps=30, metrics=None)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
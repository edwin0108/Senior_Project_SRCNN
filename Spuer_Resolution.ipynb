{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spuer_Resolution.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "etoWJCqqBBJq"
      },
      "cell_type": "markdown",
      "source": [
        "# Import Section"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "BuXTXaiWBBQK",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Path\n",
        "import os\n",
        "\n",
        "# Timer\n",
        "import time\n",
        "\n",
        "# Math\n",
        "import math\n",
        "\n",
        "# Data\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# Plot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Image\n",
        "from PIL import Image # used in image processing function\n",
        "from PIL import ImageFilter # used in load_image_pair()\n",
        "\n",
        "# Tensorflow\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "\n",
        "# For Tensorflow Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, PReLU, Conv2DTranspose\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.initializers import RandomNormal\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "pAr52j3pAKOZ"
      },
      "cell_type": "markdown",
      "source": [
        "# Colab Function"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "7BI277Ug8aiC",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def gpu_check():\n",
        "  \"\"\"\n",
        "    check your gpu is available:\n",
        "  \"\"\"\n",
        "  import torch # we are using tensorflow, I import torch here just becuase torch.device() works better with colab.\n",
        "  \n",
        "  # setting device on GPU if available, else CPU\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  print('Using device:', device)\n",
        "  print()\n",
        "\n",
        "  #Additional Info when using cuda\n",
        "  if device.type == 'cuda':\n",
        "      print(torch.cuda.get_device_name(0))\n",
        "      print('Memory Usage:')\n",
        "      print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "      print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "jCYudY3lCm9Y"
      },
      "cell_type": "markdown",
      "source": [
        "# Path Functions"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "m8cFuFGVCmUi",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def ensure_dir(path_to_dir):\n",
        "  try:\n",
        "      os.makedirs(path_to_dir)\n",
        "  except FileExistsError:\n",
        "      # directory already exists\n",
        "      pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Cy0RU340NMu7"
      },
      "cell_type": "markdown",
      "source": [
        "# Config"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aC2LlAquNz8_",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "    config project in this cell.\n",
        "\"\"\"\n",
        "\n",
        "# Env, where you running this project\n",
        "# Google colab: 'colab'\n",
        "# local machine: 'local'\n",
        "# google cloud deep learning VM: 'gcpvm'\n",
        "env = 'gcpvm'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-RshcPfONLU2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\" \n",
        "     _______________________________________________\n",
        "    | YOU SHOULD NOT CHANGE ANY THING IN THIS CELL. |\n",
        "    |_______________________________________________|\n",
        "\"\"\"\n",
        "\n",
        "# config dictionary\n",
        "config = {\n",
        "    'colab':{\n",
        "        'data_dir':'/content/drive/My Drive/Colab Notebooks/data',\n",
        "        'checkpoint_dir':'/content/drive/My Drive/Colab Notebooks/checkpoints',\n",
        "        'log_dir':'/content/drive/My Drive/Colab Notebooks/logs',\n",
        "        'predict_dir':'/content/drive/My Drive/Colab Notebooks/prediction',\n",
        "        'result_dir':'/content/drive/My Drive/Colab Notebooks/result',\n",
        "        'result_demo_dir': '/content/drive/My Drive/Colab Notebooks/result_demo'\n",
        "    },\n",
        "    'local':{\n",
        "        'data_dir': os.path.join(os.getcwd(), 'data'),\n",
        "        'checkpoint_dir': os.path.join(os.getcwd(), 'checkpoints'),\n",
        "        'log_dir': os.path.join(os.getcwd(), 'logs'),\n",
        "        'predict_dir':os.path.join(os.getcwd(), 'prediction'),\n",
        "        'result_dir':os.path.join(os.getcwd(), 'result'),\n",
        "        'result_demo_dir': os.path.join(os.getcwd(), 'result_demo'),\n",
        "    },\n",
        "    'gcpvm':{\n",
        "        'data_dir': os.path.join('/home/Weicheng', 'data'),\n",
        "        'checkpoint_dir': os.path.join('/home/Weicheng/downloads', 'checkpoints'),\n",
        "        'log_dir': os.path.join('/home/Weicheng/downloads', 'logs'),\n",
        "        'predict_dir':os.path.join('/home/Weicheng/downloads', 'prediction'),\n",
        "        'result_dir':os.path.join('/home/Weicheng/downloads', 'result'),\n",
        "        'result_demo_dir': os.path.join('/home/Weicheng/downloads', 'result_demo'),\n",
        "    }\n",
        "}\n",
        "\n",
        "# setting all variables\n",
        "data_dir = config[env]['data_dir']\n",
        "checkpoint_dir = config[env]['checkpoint_dir']\n",
        "log_dir = config[env]['log_dir']\n",
        "predict_dir = config[env]['predict_dir']\n",
        "result_dir = config[env]['result_dir']\n",
        "result_demo_dir = config[env]['result_demo_dir']\n",
        "\n",
        "# mount google drive\n",
        "if env == 'colab':\n",
        "  # Google Drive\n",
        "  from google.colab import drive\n",
        "  # mount google dirve\n",
        "  drive.mount('/content/drive')\n",
        "  # check GPU\n",
        "  # gpu_check()\n",
        "  \n",
        "# make sure dir exist\n",
        "ensure_dir(checkpoint_dir)\n",
        "ensure_dir(log_dir)\n",
        "ensure_dir(predict_dir)\n",
        "ensure_dir(result_dir)\n",
        "ensure_dir(result_demo_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "kDu_20FxAARs"
      },
      "cell_type": "markdown",
      "source": [
        "# Image Processing Function"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "c_98TDEO_pzJ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def bicubic_rescale(image, scale):\n",
        "  \"\"\"\n",
        "      Rescale image using bicubic interpolation.\n",
        "      \n",
        "      Args:\n",
        "        image: image\n",
        "        scale: use integer for up scaling. use 1/integer for down scaling\n",
        "  \"\"\"\n",
        "  # make sure scale is valid\n",
        "  if isinstance(scale, (float, int)):\n",
        "    size = (np.array(image.size) * scale).astype(int)\n",
        "  return image.resize(size, resample=Image.BICUBIC)\n",
        "\n",
        "\n",
        "def modcrop(image, scale):\n",
        "  \"\"\"\n",
        "      To scale down the original image, there must be no remainder while scaling\n",
        "      operation.\n",
        "      \n",
        "      All we want to do in here is to subtract the remainder from height and \n",
        "      width of original image size, and cut the original image to the new size.\n",
        "      \n",
        "      Args:\n",
        "        image: original image\n",
        "        scale: must be int\n",
        "  \"\"\"\n",
        "  if not isinstance(scale, int):\n",
        "    raise Exception('Image Processing Function.modcrop: scale must be int')\n",
        "  size = np.array(image.size)\n",
        "  size -= size % scale\n",
        "  return image.crop([0, 0, *size])\n",
        "\n",
        "def centercrop(image, size):\n",
        "  \"\"\"\n",
        "      To crop the image from center.\n",
        "      \n",
        "      Args:\n",
        "        size: the size of image after crop, Size for both height and width.\n",
        "  \"\"\"\n",
        "  width, height = image.size\n",
        "\n",
        "  left = (width - size)/2\n",
        "  top = (height - size)/2\n",
        "  right = (width + size)/2\n",
        "  bottom = (height + size)/2\n",
        "  \n",
        "  if not all(isinstance(i, int) for i in [left, top, right, bottom]):\n",
        "    if not all(int(i) == i for i in [left, top, right, bottom]):\n",
        "      raise Exception('Image Processing Function.centercrop: with this size, image can not precisely crop at the center')\n",
        "\n",
        "  return image.crop([left, top, right, bottom])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "kQdMEWBzeZUZ"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Q2pYcMrkefv7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def img_to_array(img):\n",
        "  \"\"\"\n",
        "    convert image to array using tensorflow.keras.preprocessing.image.img_to_array, then normalized data to range(0, 1).\n",
        "  \"\"\"\n",
        "  array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "  return array/255\n",
        "\n",
        "\n",
        "def array_to_img(array):\n",
        "  \"\"\"\n",
        "    scale a array to range(0, 255), then convert array to image using tensorflow.keras.preprocessing.image.array_to_img.\n",
        "  \"\"\"\n",
        "  # make any number smaller than 0 to be 0 and any number bigger than 255 to be 255\n",
        "  np.clip(array, 0, 255)\n",
        "  return tf.keras.preprocessing.image.array_to_img(array)\n",
        "  \n",
        "\n",
        "\n",
        "def load_image_pair(path, scale=3, greyscale=False, same_size=False):\n",
        "  \"\"\"\n",
        "      Down scaling a hight resolution image to a low resolution image and\n",
        "      return both of them.\n",
        "      \n",
        "      Args:\n",
        "        path: image path\n",
        "        scale: scale of down scaling, must be a int\n",
        "        greyscale: return only Y channel\n",
        "  \"\"\"\n",
        "  image = load_img(path)\n",
        "  \n",
        "  if greyscale:\n",
        "    image = image.convert('YCbCr')\n",
        "    Y, Cb, Cr = image.split()\n",
        "    image = Y\n",
        "  else:\n",
        "    image = image.convert('RGB')\n",
        "\n",
        "  hr_image = modcrop(image, scale)\n",
        "#  lr_image = hr_image.filter(ImageFilter.GaussianBlur(radius=2))\n",
        "  lr_image = bicubic_rescale(hr_image, 1 / scale)\n",
        "  if same_size:\n",
        "    lr_image = bicubic_rescale(lr_image, scale)\n",
        "  return lr_image, hr_image\n",
        "\n",
        "\n",
        "# def random_crop(lr_image, hr_image, random_crop_size):\n",
        "#   \"\"\"\n",
        "#       randomly crop both lr and hr image at the same position.\n",
        "      \n",
        "#       Args:\n",
        "#           random_crop_size: size of sub image, array, example:[32,32]\n",
        "#   \"\"\"\n",
        "#   # Note: image_data_format is 'channel_last'\n",
        "#   height, width = lr_image.size\n",
        "#   dy, dx = random_crop_size\n",
        "#   x = np.random.randint(0, width - dx + 1)\n",
        "#   y = np.random.randint(0, height - dy + 1)\n",
        "#   return lr_image.crop([x, y, x + dx, y + dy]), hr_image.crop([x, y, x + dx, y + dy])\n",
        "\n",
        "def random_crop(image, random_crop_size):\n",
        "  \"\"\"\n",
        "      randomly crop both lr and hr image at the same position.\n",
        "      \n",
        "      Args:\n",
        "          random_crop_size: size of sub image, array, example:[32,32]\n",
        "  \"\"\"\n",
        "  # Note: image_data_format is 'channel_last'\n",
        "  height, width = image.size\n",
        "  dy, dx = random_crop_size\n",
        "  x = np.random.randint(0, width - dx + 1)\n",
        "  y = np.random.randint(0, height - dy + 1)\n",
        "  return image.crop([x, y, x + dx, y + dy])\n",
        "\n",
        "\n",
        "def generate_sub_images(image, size, stride):\n",
        "  \"\"\"\n",
        "      Cut image into sub images.\n",
        "      \n",
        "      Args:\n",
        "        image: image\n",
        "        size: size of sub image\n",
        "        stride: distance of how much the window shifts by in each of the \n",
        "                dimensions\n",
        "  \"\"\"\n",
        "  for i in range(0, image.size[0] - size + 1, stride):\n",
        "        for j in range(0, image.size[1] - size + 1, stride):\n",
        "            # yield return a generator, or a list of number\n",
        "            yield image.crop([i, j, i + size, j + size])\n",
        "            \n",
        "            \n",
        "class Dataset:\n",
        "  \n",
        "  def __init__(self):\n",
        "    self.lr_sub_size = 0\n",
        "    self.lr_sub_stride = 0\n",
        "    self.hr_sub_size = 0\n",
        "    self.hr_sub_stride = 0\n",
        "    self.lr_images = []\n",
        "    self.hr_images = []\n",
        "    self.greyscale = False\n",
        "    self.same_size = False\n",
        "    \n",
        "    \n",
        "  def load_set(self, dataset_name, same_size, greyscale=False):\n",
        "    \"\"\"\n",
        "        Load all image from a directory.\n",
        "\n",
        "        Args:\n",
        "          dataset_name: name of dir of the data set\n",
        "          lr_sub_size: low resolution sub image size\n",
        "          lr_sub_stride: stride when crop sub image\n",
        "          scale: down scale value\n",
        "          same_size: hr, lr have the same size\n",
        "          greyscale: return only Y channel\n",
        "    \"\"\"\n",
        "    self.greyscale = greyscale\n",
        "    self.same_size = same_size\n",
        "    \n",
        "    # set up progress bar\n",
        "    file_num = len([file_name for file_name in os.listdir(os.path.join(data_dir, dataset_name))])\n",
        "    progress_bar = tf.keras.utils.Progbar(file_num)\n",
        "    jobs_done = 0\n",
        "    print('load_set: ')\n",
        "    \n",
        "    for file_name in os.listdir(os.path.join(data_dir, dataset_name)):\n",
        "      path = os.path.join(data_dir, dataset_name, file_name)\n",
        "      lr_image, hr_image = load_image_pair(str(path), scale=scale, greyscale=self.greyscale, same_size=self.same_size)\n",
        "      self.lr_images.append(lr_image)\n",
        "      self.hr_images.append(hr_image)\n",
        "      \n",
        "      jobs_done += 1\n",
        "      progress_bar.update(jobs_done)\n",
        "     \n",
        "    print()\n",
        "      \n",
        "      \n",
        "  def show_set(self):\n",
        "    \"\"\"\n",
        "      view the first 3 image of the dataset\n",
        "    \"\"\"\n",
        "    if self.greyscale:\n",
        "      colormap = 'gray'\n",
        "    else:\n",
        "      colormap = None\n",
        "      \n",
        "    f, axarr = plt.subplots(2, 3, figsize=(18,18))\n",
        "    \n",
        "    # Plot images in subplot\n",
        "    axarr[1,2].imshow(self.hr_images[0], cmap=colormap)\n",
        "    axarr[1,1].imshow(self.hr_images[1], cmap=colormap)\n",
        "    axarr[1,0].imshow(self.hr_images[2], cmap=colormap)\n",
        "    axarr[0,2].imshow(self.lr_images[0], cmap=colormap)\n",
        "    axarr[0,1].imshow(self.lr_images[1], cmap=colormap)\n",
        "    axarr[0,0].imshow(self.lr_images[2], cmap=colormap)\n",
        "    \n",
        "    # Disable axis\n",
        "    axarr[1,2].axis(\"off\")\n",
        "    axarr[1,1].axis(\"off\")\n",
        "    axarr[1,0].axis(\"off\")\n",
        "    axarr[0,2].axis(\"off\")\n",
        "    axarr[0,1].axis(\"off\")\n",
        "    axarr[0,0].axis(\"off\")\n",
        "   \n",
        "    plt.show()\n",
        "    \n",
        "  def sub_image_set_random(self, lr_sub_size, hr_sub_size, scale, num_of_image=1):\n",
        "    \"\"\"\n",
        "      return the sub image dataset, sub image crop randomly\n",
        "    \"\"\"\n",
        "    lr_sub_arrays = []\n",
        "    hr_sub_arrays = []\n",
        "    lr_batch = []\n",
        "    hr_batch = []\n",
        "    height, width = self.hr_images[0].size\n",
        "    dx = lr_sub_size\n",
        "    dy = lr_sub_size\n",
        "\n",
        "    # crop low resolution image and high resolution image at same position\n",
        "    for lr_image, hr_image in zip(self.lr_images, self.hr_images):\n",
        "      for i in range(num_of_image):\n",
        "        x = np.random.randint(0, width - dx + 1)\n",
        "        y = np.random.randint(0, height - dy + 1)\n",
        "\n",
        "        lr_batch += [lr_image.crop([x, y, x + dx, y + dy])]\n",
        "        hr_batch += [hr_image.crop([x, y, x + dx, y + dy])]\n",
        "        \n",
        "      # crop high resolution image\n",
        "      if lr_sub_size !=  hr_sub_size:\n",
        "        for i in range(len(hr_batch)):\n",
        "          hr_batch[i] = centercrop(hr_batch[i], hr_sub_size)\n",
        "\n",
        "      lr_sub_arrays += [tf.keras.preprocessing.image.img_to_array(img) for img in lr_batch]\n",
        "      hr_sub_arrays += [tf.keras.preprocessing.image.img_to_array(img) for img in hr_batch]\n",
        "\n",
        "    # convert list to np.array\n",
        "    x = np.stack(lr_sub_arrays)\n",
        "    y = np.stack(hr_sub_arrays)\n",
        "\n",
        "    return x, y \n",
        "    \n",
        "  \n",
        "  def sub_image_set(self, lr_sub_size, hr_sub_size, lr_sub_stride, scale):\n",
        "    \"\"\"\n",
        "      return the normalized sub image array dataset, \n",
        "    \"\"\"\n",
        "    lr_sub_arrays = []\n",
        "    hr_sub_arrays = []\n",
        "\n",
        "    # compute parameters for high resolution image\n",
        "    if self.same_size:\n",
        "      _hr_sub_size = lr_sub_size\n",
        "      _hr_sub_stride = lr_sub_stride\n",
        "    else:\n",
        "      _hr_sub_size = lr_sub_size * scale\n",
        "      _hr_sub_stride = lr_sub_stride * scale\n",
        "      \n",
        "    # set up progress bar\n",
        "    file_num = len(self.hr_images)\n",
        "    progress_bar = tf.keras.utils.Progbar(file_num)\n",
        "    jobs_done = 0\n",
        "    print('sub_image_set:')\n",
        "\n",
        "    for lr_image, hr_image in zip(self.lr_images, self.hr_images):\n",
        "      # make low resolution sub image set\n",
        "      lr_sub_arrays += [tf.keras.preprocessing.image.img_to_array(img) for img in generate_sub_images(lr_image, size=lr_sub_size, stride=lr_sub_stride)]\n",
        "      \n",
        "      # make high resolution sub image set\n",
        "      hr_sub_images = list(generate_sub_images(hr_image, size=_hr_sub_size, stride=_hr_sub_stride))\n",
        "      # crop high resolution image\n",
        "      if lr_sub_size !=  hr_sub_size:\n",
        "        for i in range(len(hr_sub_images)):\n",
        "          hr_sub_images[i] = centercrop(hr_sub_images[i], hr_sub_size)\n",
        "      # store sub image\n",
        "      hr_sub_arrays += [tf.keras.preprocessing.image.img_to_array(img) for img in hr_sub_images]\n",
        "      \n",
        "      jobs_done += 1\n",
        "      progress_bar.update(jobs_done)\n",
        "\n",
        "    print()\n",
        "    \n",
        "    # convert list to np.array\n",
        "    x = np.stack(lr_sub_arrays)\n",
        "    y = np.stack(hr_sub_arrays)\n",
        "\n",
        "    return x, y \n",
        "\n",
        "  def clear_set(self):\n",
        "    \"\"\"\n",
        "      reset Dataset\n",
        "    \"\"\"\n",
        "    self.lr_images = []\n",
        "    self.hr_images = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9rCtq3ur2fBt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Keras Callbacks"
      ]
    },
    {
      "metadata": {
        "id": "sCzBfp432eDt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NEpochsLogger(tf.keras.callbacks.Callback):\n",
        "  \"\"\"\n",
        "  A Logger that log average performance per `display` steps.\n",
        "  \"\"\"\n",
        "  def __init__(self, display):\n",
        "      self.display = display\n",
        "      self.last_epoch_time = 0\n",
        "\n",
        "  def on_epoch_end(self, epoch, log={}):\n",
        "      if epoch % self.display == 0:\n",
        "        epoch_time = (time.time() - self.last_epoch_time)/100\n",
        "        remain_time = (self.params['epochs'] - epoch) * epoch_time /3600\n",
        "        print('epochs: {0}/{1} ... {2}, time left: {3:0.4f} hours'.format(epoch, self.params['epochs'], log, remain_time))\n",
        "        self.last_epoch_time = time.time()\n",
        "            \n",
        "            \n",
        "class TrainTimeLogger(tf.keras.callbacks.Callback):\n",
        "  \"\"\"\n",
        "    A Logger that log total training time.\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    self.start_time = time.time()\n",
        "    \n",
        "  def on_train_end(self, log=None):\n",
        "    print('_________________________________________________________________')\n",
        "    print('Total training time: {0:.4f} hours.'.format((time.time() - self.start_time)/3600))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "_YdOAzDpH50m"
      },
      "cell_type": "markdown",
      "source": [
        "# Helper Function"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6ra2c266H5U5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(\n",
        "    model,\n",
        "    train_set,\n",
        "    val_set,\n",
        "    epochs=1,\n",
        "    steps_per_epoch=30,\n",
        "    validation_steps=3,\n",
        "    resume=True):\n",
        "  \"\"\"\n",
        "    train function for all model.\n",
        "    \n",
        "    \n",
        "  \"\"\"\n",
        "  path_to_weight_file = os.path.join(checkpoint_dir,model.name)\n",
        "\n",
        "  # define callbacks\n",
        " \n",
        "    # Save checkpoints of model at regular intervals\n",
        "  callbacks = [\n",
        "    # Save checkpoints of model at regular intervals\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=path_to_weight_file,\n",
        "        save_best_only=True\n",
        "    ),\n",
        "    # Write TensorBoard logs to `./logs` directory with additional features\n",
        "    tf.keras.callbacks.TensorBoard(log_dir=log_dir,\n",
        "                                   histogram_freq = 100,\n",
        "                                   write_graph=True,\n",
        "                                   write_images=True,\n",
        "                                   update_freq='epoch'\n",
        "    ),\n",
        "    # display loss result every 100 epochs\n",
        "    NEpochsLogger(100),\n",
        "    # time logger\n",
        "    TrainTimeLogger()\n",
        "  ]\n",
        "  \n",
        "  # inherit weights\n",
        "  \n",
        "  if resume:\n",
        "    reload_model(model)\n",
        "  \n",
        "  # Train\n",
        "  #callbacks.set_model(model)\n",
        "\n",
        "  history = model.fit(train_set, epochs=epochs,verbose=0, callbacks=callbacks, steps_per_epoch=steps_per_epoch,\n",
        "            validation_data=val_set, validation_steps=validation_steps)\n",
        "  \n",
        "\n",
        "def test(model, test_set, steps=30, metrics=None):\n",
        "  # test\n",
        "  reload_model(model)\n",
        "  model.evaluate(test_set, steps=steps)\n",
        "  \n",
        "  \n",
        "def predict(model_class, greyscale=False):\n",
        "  \"\"\"\n",
        "    reload images from predict_dir and save ouput images to result_dir.\n",
        "  \"\"\"\n",
        "  predict_arrays = []\n",
        "  result_images = []\n",
        "  \n",
        "  # Load images from predict directory\n",
        "  dataset = Dataset()\n",
        "  dataset.load_set(predict_dir, True, greyscale)\n",
        "  \n",
        "  # Predict images\n",
        "  for img in dataset.hr_images:\n",
        "    result_image = predict_an_image(model_class, img)\n",
        "    result_images.append(result_image)\n",
        "  \n",
        "  # Save result_images\n",
        "  for i in range(len(result_images)):\n",
        "    filename = str(i) + '.bmp'\n",
        "    result_images[i].save( os.path.join(result_dir, filename) )\n",
        "    print(filename + ' saved to ' + result_dir)\n",
        "\n",
        "\n",
        "def predict_an_image(model_class, image):\n",
        "  \"\"\"\n",
        "    predict one image using model_class.model\n",
        "  \"\"\"\n",
        "  predict_array = tf.keras.preprocessing.image.img_to_array(image)\n",
        "  \n",
        "  # Convert image array to a 4D array\n",
        "  predict_array = np.expand_dims(predict_array, axis=0)\n",
        "  \n",
        "  # Model\n",
        "  model = model_class.build_model(image.size, padding=True)\n",
        "  \n",
        "  # Reload weight\n",
        "  reload_model(model)\n",
        "  \n",
        "  # Prediction\n",
        "  result_arrays = model.predict(predict_array, batch_size=1, verbose=1)\n",
        "  \n",
        "  # return an image\n",
        "  return array_to_img(result_arrays[0])\n",
        "\n",
        "\n",
        "def result_demo(data_dir, model_class, same_size=True, greyscale=False):\n",
        "  \"\"\"\n",
        "    take all images from dir, make low resolution image from those image then predict it using model.\n",
        "    Save high resolution image, low resolution image and prediction image in result_demo_dir.\n",
        "  \"\"\"\n",
        "  dataset = Dataset()\n",
        "  \n",
        "  # load high resolution image and make low resolution image\n",
        "  dataset.load_set(data_dir, same_size, greyscale)\n",
        "  \n",
        "  # get predict images\n",
        "  result_images = []\n",
        "  for img in dataset.lr_images:\n",
        "    result_image = predict_an_image(model_class, img)\n",
        "    result_images.append(result_image)\n",
        "    \n",
        "  # save high resolution images\n",
        "  for i in range(len(dataset.hr_images)):\n",
        "    filename = str(i) + '_hr' + '.bmp'\n",
        "    dataset.hr_images[i].save( os.path.join(result_demo_dir, filename) )\n",
        "    print(filename + ' saved to ' + result_demo_dir)\n",
        "    \n",
        "  # save prediction images\n",
        "  for i in range(len(result_images)):\n",
        "    filename = str(i) + '_pred' + '.bmp'\n",
        "    result_images[i].save( os.path.join(result_demo_dir, filename) )\n",
        "    print(filename + ' saved to ' + result_demo_dir)\n",
        "    \n",
        "  # save low resolution images\n",
        "  for i in range(len(dataset.lr_images)):\n",
        "    filename = str(i) + '_lr' + '.bmp'\n",
        "    dataset.lr_images[i].save( os.path.join(result_demo_dir, filename) )\n",
        "    print(filename + ' saved to ' + result_demo_dir)\n",
        "    \n",
        "  print('______________________________________________')\n",
        "  for i in range(len(dataset.hr_images)):\n",
        "    print('images_' + str(i) + ': (hr / pred) ' + str(psnr_img(dataset.hr_images[i], result_images[i])))\n",
        "  \n",
        "  \n",
        "def reload_model(model):\n",
        "  \"\"\"\n",
        "    load weight into model\n",
        "  \"\"\"\n",
        "  try:\n",
        "    print(\"Reading {} checkpoints...\".format(model.name))\n",
        "    path_to_weight_file = os.path.join(checkpoint_dir,model.name)\n",
        "    model.load_weights(path_to_weight_file)\n",
        "    \n",
        "  except:\n",
        "    raise Exception(\"Data Preprocessing.reloadmodel: Fail to load weight on model.\")\n",
        "    \n",
        "    \n",
        "def psnr_img(img1, img2):\n",
        "  \"\"\"\n",
        "  img1/img2 - images tht are being process\n",
        "  \"\"\"\n",
        "  #convert images to array before computing the mean square error\n",
        "  array_img1 = tf.keras.preprocessing.image.img_to_array(img1)\n",
        "  array_img2 = tf.keras.preprocessing.image.img_to_array(img2)\n",
        "  mse = np.mean(np.square(array_img1 - array_img2), axis=(-3, -2))\n",
        "  return np.mean(20 * np.log(255 / np.sqrt(mse)) / np.log(10))\n",
        "  \n",
        "  \n",
        "def plot_based_loss(history):\n",
        "  \"\"\"\n",
        "    Plot training & validation loss values\n",
        "    history: a dictionary recording training loss values and metrics values at successive epochs\n",
        "  \"\"\"\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('Model loss: Mean Squared Error')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "  plt.ylim(0,2000)\n",
        "  plt.show()\n",
        "  \n",
        "def plot_based_accuracy(history):\n",
        "  \"\"\"\n",
        "    Plot training & validation accuracy values\n",
        "    history: a dictionary recording training loss values and metrics values at successive epochs\n",
        "  \"\"\"\n",
        "  plt.plot(history.history['acc'])\n",
        "  plt.plot(history.history['val_acc'])\n",
        "  plt.title('Model accuracy: Accuracy')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CLLRMLJs6WSd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Metrics"
      ]
    },
    {
      "metadata": {
        "id": "U5yOqmSD6WvZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def psnr(y_true, y_pred):\n",
        "    \"\"\"\n",
        "      peak signal to noise ratio.\n",
        "    \"\"\"\n",
        "    return tf.image.psnr(y_true, y_pred, max_val=255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Njz9qRTbR2eC"
      },
      "cell_type": "markdown",
      "source": [
        "# Model"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aopmTkWXR5Yt",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# SRCNN without RGB\n",
        "class SRCNN:\n",
        "  \"\"\"\n",
        "    name: the name of the model\n",
        "    img_size: the size of the input image\n",
        "    channel: the number of channels in the input image\n",
        "    f1: the size of filter (must be odd #)\n",
        "    n1: the number of filters apply on layer 1\n",
        "    n2: the number of filters apply on layer 2\n",
        "    f3: the size of filter (must be odd #)\n",
        "\n",
        "\n",
        "    from: https://arxiv.org/abs/1501.00092\n",
        "  \"\"\" \n",
        "  def build_model(self, size, padding, channel=1, f1=9, f2=1, f3=5, n1=64, n2=32):\n",
        "    if padding:\n",
        "      padding = 'same'\n",
        "    else:\n",
        "      padding = 'valid'\n",
        "    \n",
        "    model = Sequential(name='srcnn')\n",
        "    initializer = RandomNormal(mean=0.0, stddev=0.001)\n",
        "    model.add(Conv2D(filters=n1, kernel_size=f1, padding=padding, activation='relu', \n",
        "                     kernel_initializer=initializer, input_shape=(size[1], size[0], channel)))\n",
        "    model.add(Conv2D(filters=n2, kernel_size=f2, padding=padding, activation='relu',\n",
        "                     kernel_initializer=initializer))\n",
        "    model.add(Conv2D(filters=channel, kernel_size=f3, padding=padding, activation='linear',\n",
        "                     kernel_initializer=initializer))\n",
        "  \n",
        "    # either SGD or Adam\n",
        "    #optimizer = SGD(lr=0.00001)\n",
        "    optimizer = Adam(lr=0.00001, decay=0.00001)\n",
        "    # we would want to use different learning for each layer. However, I did not find how to implement this in keras.\n",
        "    # As for now, we are using Adaptive Moment Estimation(Adam) to compute adaptive learning rates for each parameter.\n",
        "    # Hopefully it works.\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=[psnr])\n",
        "      \n",
        "    return model\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uAqewoqcDGNG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# SRCNN with RGB\n",
        "class SRCNNRGB:\n",
        "  \"\"\"\n",
        "    name: the name of the model\n",
        "    img_size: the size of the input image\n",
        "    channel: the number of channels in the input image\n",
        "    f1: the size of filter (must be odd #)\n",
        "    n1: the number of filters apply on layer 1\n",
        "    n2: the number of filters apply on layer 2\n",
        "    f3: the size of filter (must be odd #)\n",
        "\n",
        "\n",
        "    from: https://arxiv.org/abs/1501.00092\n",
        "  \"\"\" \n",
        "  def build_model(self, size, padding, channel=3, f1=9, f2=5, f3=5, n1=64, n2=32):\n",
        "    if padding:\n",
        "      padding = 'same'\n",
        "    else:\n",
        "      padding = 'valid'\n",
        "    \n",
        "    model = Sequential(name='srcnn with rgb')\n",
        "    initializer = RandomNormal(mean=0.0, stddev=0.001)\n",
        "    model.add(Conv2D(filters=n1, kernel_size=f1, padding=padding, activation='relu', \n",
        "                     kernel_initializer=initializer, input_shape=(size[1], size[0], channel)))\n",
        "    model.add(Conv2D(filters=n2, kernel_size=f2, padding=padding, activation='relu',\n",
        "                     kernel_initializer=initializer))\n",
        "    model.add(Conv2D(filters=channel, kernel_size=f3, padding=padding, activation='linear',\n",
        "                     kernel_initializer=initializer))\n",
        "  \n",
        "    # either SGD or Adam\n",
        "    #optimizer = SGD(lr=0.00001)\n",
        "    optimizer = Adam(lr=0.00001, decay=0.00001)\n",
        "    # we would want to use different learning for each layer. However, I did not find how to implement this in keras.\n",
        "    # As for now, we are using Adaptive Moment Estimation(Adam) to compute adaptive learning rates for each parameter.\n",
        "    # Hopefully it works.\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=[psnr])\n",
        "      \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fv9JXIK3g2CG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# FSRCNN with RGB\n",
        "class FSRCNN:\n",
        "  \"\"\"\n",
        "    size: the size of the input image\n",
        "    padding: valid or same\n",
        "    channel: the number of channels in the input image\n",
        "    d: sensitive variable where s < d\n",
        "    s: sensitive variable where s < d\n",
        "    m: non-linear mapping \n",
        "    k: stride last layer for factor of 3\n",
        "    f: the size of filter (must be odd #)\n",
        "    n: the number of filters apply on particular layer\n",
        "    \n",
        "    \n",
        "    from: https://arxiv.org/abs/1608.00367\n",
        "  \"\"\" \n",
        "  def build_model(self, size, padding, d=56, s=16, m=4, scale=3):\n",
        "    # init parameters\n",
        "    # This is a RGB model with 3 color channel\n",
        "    c = 3\n",
        "    f = [5, 1] + [3] * m + [1]\n",
        "    n = [d, s] + [s] * m + [d]\n",
        "    \n",
        "    if padding:\n",
        "      padding = 'same'\n",
        "    else:\n",
        "      padding = 'valid'\n",
        "    \n",
        "    model = Sequential(name='fsrcnn')\n",
        "    initializer = RandomNormal(mean=0.0, stddev=0.001)\n",
        "    \n",
        "    # init tensor shape\n",
        "    model.add(tf.keras.layers.InputLayer(input_shape=[size[1], size[0], c]))\n",
        "    \n",
        "    # add convolution layer\n",
        "    for fi, ni in zip(f, n):\n",
        "      model.add(Conv2D(filters=ni, kernel_size=fi, padding=padding, kernel_initializer=initializer))\n",
        "      model.add(tf.keras.layers.BatchNormalization())\n",
        "      model.add(tf.keras.layers.PReLU(shared_axes=[1, 2]))\n",
        "    \n",
        "    # add deconvolution layer\n",
        "    model.add(Conv2DTranspose(filters=c, kernel_size=9, padding=padding, strides=scale,\n",
        "                              kernel_initializer=initializer))\n",
        "  \n",
        "    # either SGD or Adam\n",
        "    #optimizer = SGD(lr=0.00001)\n",
        "    optimizer = Adam(lr=0.0001, decay=0.0001)\n",
        "    # we would want to use different learning for each layer. However, I did not find how to implement this in keras.\n",
        "    # As for now, we are using Adaptive Moment Estimation(Adam) to compute adaptive learning rates for each parameter.\n",
        "    # Hopefully it works.\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=[psnr])\n",
        "    \n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "2cgYjtF81t1s"
      },
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "SGkYBCzi2AWC"
      },
      "cell_type": "markdown",
      "source": [
        "## Model Config"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "h9UOu_Bm1uPg",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# --------------------------- Dataset Config ---------------------------\n",
        "# size of sub image\n",
        "size = 32\n",
        "\n",
        "# strde when crop image\n",
        "stride = 14\n",
        "\n",
        "# upscaling factor\n",
        "scale = 3\n",
        "\n",
        "# size of low resolution and high resolution image is the same?\n",
        "same_size = False\n",
        "\n",
        "# randomly crop image\n",
        "randomly_crop = False\n",
        "\n",
        "# number of sub image of each image, used when randomly crop is ON\n",
        "number_of_image = 30\n",
        "\n",
        "# greyscale ON or OFF? if ON, img will only contain Y channel\n",
        "greyscale = False\n",
        "\n",
        "# which training dataset you want to use?\n",
        "train_dataset_dir = '91-image'\n",
        "\n",
        "# which validation dataset you want to use?\n",
        "val_dataset_dir = 'Set14'\n",
        "\n",
        "# which testing dataset you want to use?\n",
        "test_dataset_dir = 'Set5'\n",
        "\n",
        "# --------------------------- Model Config ---------------------------\n",
        "\n",
        "# When model class you want to use?\n",
        "model_class =  FSRCNN()\n",
        "\n",
        "# Padding setting:\n",
        "# 1. traning padding:\n",
        "training_padding = True\n",
        "# 2. testing padding:\n",
        "test_padding = True\n",
        "\n",
        "# Output layer setting:\n",
        "# 1. traning output size:\n",
        "training_output_size = 32\n",
        "# 2. testing output size:\n",
        "test_output_size = 32\n",
        "\n",
        "# Learning rate multiplier\n",
        "\n",
        "# --------------------------- Training  Config ---------------------------\n",
        "\n",
        "# epochs for traning\n",
        "epochs = 15000\n",
        "\n",
        "# batch size\n",
        "train_batch = 512\n",
        "val_batch = 512\n",
        "test_batch = 128\n",
        "\n",
        "# steps_per_epoch\n",
        "train_steps = 43\n",
        "val_steps = 29\n",
        "test_steps = 20\n",
        "\n",
        "# resume last traning?\n",
        "resume = False\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "p2KU8_I55mV_"
      },
      "cell_type": "markdown",
      "source": [
        "## Make Data"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "PXgxe40I4OWB",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\" \n",
        "     _______________________________________________\n",
        "    | YOU SHOULD NOT CHANGE ANY THING IN THIS CELL. |\n",
        "    |_______________________________________________|\n",
        "\"\"\"\n",
        "dataset = Dataset()\n",
        "\n",
        "# load tranning dataset\n",
        "dataset.load_set(train_dataset_dir, same_size, greyscale)\n",
        "dataset.show_set()\n",
        "if randomly_crop:\n",
        "  train_lr, train_hr = dataset.sub_image_set_random(size, training_output_size, scale, number_of_image)\n",
        "else:\n",
        "  train_lr, train_hr = dataset.sub_image_set(size, training_output_size, stride, scale)\n",
        "\n",
        "# make tf.data dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_lr, train_hr))\n",
        "train_dataset = train_dataset.batch(train_batch)\n",
        "train_dataset = train_dataset.repeat()\n",
        "\n",
        "# load validation dataset\n",
        "dataset.clear_set()\n",
        "dataset.load_set(val_dataset_dir, same_size, greyscale)\n",
        "if randomly_crop:\n",
        "  val_lr, val_hr = dataset.sub_image_set_random(size, training_output_size, scale, number_of_image)\n",
        "else:\n",
        "  val_lr, val_hr = dataset.sub_image_set(size, training_output_size, stride, scale)\n",
        "\n",
        "# make tf.data dataset\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_lr, val_hr))\n",
        "val_dataset = val_dataset.batch(val_batch)\n",
        "val_dataset = val_dataset.repeat()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qEco354UZowl",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\" \n",
        "    _________\n",
        "    | Train |\n",
        "    ————-\n",
        "     _______________________________________________\n",
        "    | YOU SHOULD NOT CHANGE ANY THING IN THIS CELL. |\n",
        "    |_______________________________________________|\n",
        "\"\"\"\n",
        "model = model_class.build_model([size, size], training_padding)\n",
        "\n",
        "# print model details below\n",
        "print(\"Model Name: {}\".format(model.name))\n",
        "model.summary()\n",
        "\n",
        "train(model, train_dataset, val_dataset, epochs, train_steps, val_steps, resume)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-DShHp24VRFR",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\" \n",
        "     _______________________________________________\n",
        "    | YOU SHOULD NOT CHANGE ANY THING IN THIS CELL. |\n",
        "    |_______________________________________________|\n",
        "\"\"\"\n",
        "dataset = Dataset()\n",
        "\n",
        "# load test dataset\n",
        "dataset.load_set(test_dataset_dir, same_size, greyscale)\n",
        "dataset.show_set()\n",
        "if randomly_crop:\n",
        "  test_lr, test_hr = dataset.sub_image_set_random(size, test_output_size, scale, number_of_image)\n",
        "else:\n",
        "  test_lr, test_hr = dataset.sub_image_set(size, test_output_size, stride, scale)\n",
        "\n",
        "# make tf.data dataset\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_lr, test_hr))\n",
        "test_dataset = test_dataset.batch(test_batch)\n",
        "test_dataset = test_dataset.repeat()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Zxbfh3taVMfZ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\" \n",
        "    _________\n",
        "    | Test  |\n",
        "    ---------\n",
        "     _______________________________________________\n",
        "    | YOU SHOULD NOT CHANGE ANY THING IN THIS CELL. |\n",
        "    |_______________________________________________|\n",
        "\"\"\"\n",
        "model = model_class.build_model([size, size], test_padding)\n",
        "\n",
        "# print model details below\n",
        "print(\"Model Name: {}\".format(model.name))\n",
        "model.summary()\n",
        "\n",
        "test(model, test_dataset, steps=test_steps, metrics=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rcbfHAj0Ma2c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\" \n",
        "    _________\n",
        "    | Demo  |\n",
        "    ---------\n",
        "\"\"\"\n",
        "result_demo('Set5', model_class, same_size, greyscale)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WzKo_30CdXIA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\" \n",
        "    _______________\n",
        "    | Prediction  |\n",
        "    ---------------\n",
        "     _______________________________________________\n",
        "    | YOU SHOULD NOT CHANGE ANY THING IN THIS CELL. |\n",
        "    |_______________________________________________|\n",
        "\"\"\"\n",
        "predict(model_class, greyscale)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}